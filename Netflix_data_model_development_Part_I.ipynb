{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model developement to predict the rating of a movie: Part-I\n",
    "***\n",
    "After pre-processing and feature engineering, models were developed. As it is to predict the rating, it is a regression problem with a limitation that the target variable 0-10 instead of -inf to +inf. Different aspects of model development and optimization were adopted to obtain a most reliable model. The model development was separated into different parts taking into account the run-time. <br><br>In this Part models were developed as follows:\n",
    "\n",
    "1. **Without PCA**\n",
    "\n",
    "2. **ML models:**\n",
    "    * **Simple Linear Regression, Lasso Regression, Ridge    Regression**\n",
    "    * **Random Forest Regressor**\n",
    "    * **Gradient Boosting Regressor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the datasets\n",
    "IMDB_only = pd.read_csv('pre-processed_dataset/IMDB_only.csv', index_col = 0)\n",
    "IMDB_Kaggle_common = pd.read_csv('pre-processed_dataset/IMDB_Kaggle_common.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69458, 1089)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB_only.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2585, 1089)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB_Kaggle_common.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['duration_min', 'avg_vote', 'votes', 'reviews_from_users', 'Comedy',\n",
       "       'Family', 'Sci-Fi', 'Adventure', 'Crime', 'Reality-TV'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB_only.columns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the IMDB_only dataset into X and y for model development \n",
    "y = IMDB_only['avg_vote']\n",
    "X = IMDB_only.drop(columns = 'avg_vote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69458, 1088)\n",
      "(69458,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48620, 1088)\n",
      "(20838, 1088)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinary Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_train_predict = lr.predict(X_train)\n",
    "y_test_predict = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.930399089262735"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1060426574239.8799,\n",
       " -558557858610.9672,\n",
       " -532960910080.86115,\n",
       " -416180880899.1734,\n",
       " -407295445212.3002,\n",
       " -360066668900.0519,\n",
       " -338545712619.7192,\n",
       " -222797988918.94394,\n",
       " -216654642395.95847,\n",
       " -197912596632.8925]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(lr.coef_)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43115359380742047, -9.53224537183682e+19)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_train_predict), r2_score(y_test, y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error: 1.3965042468755584e+20\n",
      "The root mean squared error: 11817378080.080025\n",
      "The mean absolute error: 256123314.63291165\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"The mean squared error:\", mean_squared_error(y_test, y_test_predict))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"The root mean squared error:\", mean_squared_error(y_test, y_test_predict, squared = False))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"The mean absolute error:\", mean_absolute_error(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = 'teal'>The r2_score for the \"test set\" is very high. So let us do some investigation to locate any abnormality.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.3, 660691682279.8333)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(y_test), np.max(y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='teal'> The 'predicted y' value is extremely high, hence this model is seems not to be a good model.**\n",
    "**<font color = 'teal'> Hence we should try different models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.1709802805998618\n",
      "0.1811941573674245\n",
      "7.11848962207759\n",
      "1\n",
      "0.0\n",
      "-0.00026864922856795204\n",
      "5.914574249280131\n",
      "10\n",
      "0.0\n",
      "-0.00026864922856795204\n",
      "5.914574249280131\n",
      "100\n",
      "0.0\n",
      "-0.00026864922856795204\n",
      "5.914574249280131\n",
      "1000\n",
      "0.0\n",
      "-0.00026864922856795204\n",
      "5.914574249280131\n"
     ]
    }
   ],
   "source": [
    "alpha = [0.1, 1, 10, 100, 1000]\n",
    "for alp in alpha:\n",
    "    lasso1 = Lasso(alpha=alp)\n",
    "    lasso1.fit(X_train, y_train)\n",
    "    y_train_predict1 = lasso1.predict(X_train)\n",
    "    y_test_predict1 = lasso1.predict(X_test)\n",
    "    print(alp)\n",
    "    print(r2_score(y_train, y_train_predict1))\n",
    "    print(r2_score(y_test, y_test_predict1))\n",
    "    print( np.max(y_test_predict1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = 'teal'>Note: Maximum r2_score (for test):0.181, with alpha:0.1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.431153883369334\n",
      "0.4212936064712376\n",
      "9.242014734399113\n",
      "0.1\n",
      "0.4311448875698495\n",
      "0.42154448742246176\n",
      "9.239206302388212\n",
      "1\n",
      "0.4307998883455012\n",
      "0.42265587746466904\n",
      "9.20735588365735\n",
      "10\n",
      "0.42603681861733556\n",
      "0.42224526230026893\n",
      "8.964918098354392\n",
      "100\n",
      "0.397013389527722\n",
      "0.401169871320032\n",
      "8.822360110328923\n",
      "1000\n",
      "0.3505292755430103\n",
      "0.36110482692167534\n",
      "8.513199678593685\n"
     ]
    }
   ],
   "source": [
    "alpha2 = [0.01, 0.1, 1, 10, 100, 1000]\n",
    "for alp2 in alpha2:\n",
    "    Rge = Ridge(alpha=alp2)\n",
    "    Rge.fit(X_train, y_train)\n",
    "    y_train_predict2 = Rge.predict(X_train)\n",
    "    y_test_predict2 = Rge.predict(X_test)\n",
    "    print(alp2)\n",
    "    print(r2_score(y_train, y_train_predict2))\n",
    "    print(r2_score(y_test, y_test_predict2))\n",
    "    print(np.max(y_test_predict2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = 'teal'> Note: Maximum r2_score(for train): 0.430, r2_score(for test):0.442, with alpha:0.1, 10**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=None, normalize=False, random_state=None,\n",
       "                             solver='auto', tol=0.001),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'alpha': [0.01, 0.1, 1, 10]}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=False, scoring='r2', verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rge3 = Ridge()\n",
    "alpha = [0.01, 0.1, 1, 10]\n",
    "parameters = {'alpha': alpha}\n",
    "rge3_grid = GridSearchCV(Rge3, param_grid = parameters, scoring = 'r2', cv = 5)\n",
    "rge3_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4111781305702505\n",
      "{'alpha': 10}\n"
     ]
    }
   ],
   "source": [
    "print(rge3_grid.best_score_)\n",
    "print(rge3_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                                   max_iter=None, normalize=False,\n",
       "                                   random_state=None, solver='auto',\n",
       "                                   tol=0.001),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'alpha': array([1.00000000e-02, 5.27263158e+00, 1.05352632e+01, 1.57978947e+01,\n",
       "       2.10605263e+01, 2.63231579e+01, 3.15857895e+01, 3.68484211e+01,\n",
       "       4.21110526e+01, 4.73736842e+01, 5.26363158e+01, 5.78989474e+01,\n",
       "       6.31615789e+01, 6.84242105e+01, 7.36868421e+01, 7.89494737e+01,\n",
       "       8.42121053e+01, 8.94747368e+01, 9.47373684e+01, 1.00000000e+02])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='r2', verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rge4 = Ridge()\n",
    "alpha4 = {'alpha': np.linspace(0.01, 100, 20)} \n",
    "Rge4_random = RandomizedSearchCV(Rge4, param_distributions = alpha4, scoring = 'r2', cv = 5)\n",
    "Rge4_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4119995376297078\n",
      "{'alpha': 5.272631578947368}\n"
     ]
    }
   ],
   "source": [
    "print(Rge4_random.best_score_)\n",
    "print(Rge4_random.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Among all the Linear Regression models the Ridge Regression found to be most reliable with r2_score of 0.43. This score is very low. So we need to apply other regression models like Random Forest and Gradient Boosting to see other models performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(random_state = 42)\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict3 = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44038770614893497"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_predict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, y_predict3, color = 'b')\n",
    "plt.xlim([0, 10])\n",
    "plt.ylim([0, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44038770614893497\n",
      "2021-09-06 13:34:56.160567 2021-09-06 13:45:53.734697\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "start = datetime.datetime.now()\n",
    "regr2 = RandomForestRegressor(n_estimators=150, random_state = 42)\n",
    "regr.fit(X_train, y_train)\n",
    "y_predict4 = regr.predict(X_test)\n",
    "print(r2_score(y_test, y_predict4))\n",
    "end = datetime.datetime.now()\n",
    "print(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = 'teal'> Note: From above, it can be concluded that the Random Forest Regressor model performance is better than Linear Regresson model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_gradientboosting(learning_rate, n_estimator, max_features, max_depth):\n",
    "    for rate in learning_rate:\n",
    "        gb = GradientBoostingRegressor(learning_rate = rate, n_estimators = n_estimator,  max_features = max_features, max_depth = max_depth)\n",
    "        gb.fit(X_train, y_train)\n",
    "        y_gb_predict = gb.predict(X_test)\n",
    "        score_1 = r2_score(y_test, y_gb_predict)\n",
    "        print(rate)\n",
    "        print(score_1)\n",
    "    return print('End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.26661488650130916\n",
      "1\n",
      "0.38716055959870743\n",
      "10\n",
      "-2.380036098546006e+18\n",
      "End\n",
      "2021-09-06 14:30:47.513626 2021-09-06 14:31:41.846209\n"
     ]
    }
   ],
   "source": [
    "learning_rate = [0.1, 1, 10]\n",
    "start = datetime.datetime.now()\n",
    "opt_gradientboosting(learning_rate, 10, 1027, 3)\n",
    "end = datetime.datetime.now()\n",
    "print(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.3441193034946183\n",
      "1\n",
      "0.4192110927519688\n",
      "10\n",
      "-2.8426996251467216e+37\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "opt_gradientboosting(learning_rate, 20, 1027, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.405487314843786\n",
      "1\n",
      "0.430363709839758\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "learning_rate = [0.1, 1]\n",
    "opt_gradientboosting(learning_rate, 50, 1027, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.4220354538708946\n",
      "1\n",
      "0.44287293896783\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "opt_gradientboosting(learning_rate, 75, 1027, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.4306406063985203\n",
      "1\n",
      "0.4499986579437475\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "opt_gradientboosting(learning_rate, 100, 1027, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.4512881418387964\n",
      "1\n",
      "0.4527696843476695\n",
      "End\n",
      "2021-09-06 14:53:48.441762 2021-09-06 15:05:17.090728\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "opt_gradientboosting(learning_rate, 200, 1027, 3)\n",
    "end = datetime.datetime.now()\n",
    "print(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.4613471944989056\n",
      "1\n",
      "0.4543756585618456\n",
      "End\n",
      "2021-09-06 15:13:59.297184 2021-09-06 15:31:26.960782\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "learning_rate = [0.1, 1]\n",
    "opt_gradientboosting(learning_rate, 300, 1027, 3)\n",
    "end = datetime.datetime.now()\n",
    "print(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start = datetime.datetime.now()\n",
    "learning_rate = [0.1, 1]\n",
    "opt_gradientboosting(learning_rate, 400, 1027, 3)\n",
    "end = datetime.datetime.now()\n",
    "print(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.47423013558800275\n",
      "1\n",
      "0.43158176629618317\n",
      "End\n",
      "2021-09-06 16:01:36.502660 2021-09-06 16:30:31.317804\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "learning_rate = [0.1, 1]\n",
    "opt_gradientboosting(learning_rate, 500, 1027, 3)\n",
    "end = datetime.datetime.now()\n",
    "print(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='teal'> With learning_rate = 1, the r2_score has stated decreasing. Hence only learning_rate = 0.1 was only kept for further model building.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.4769977595041094\n",
      "End\n",
      "2021-09-06 16:58:54.688942 2021-09-06 17:16:53.440884\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "learning_rate = [0.1]\n",
    "opt_gradientboosting(learning_rate, 600, 1027, 3)\n",
    "end = datetime.datetime.now()\n",
    "print(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.4796443785326261\n",
      "End\n",
      "2021-09-06 17:35:17.229284 2021-09-06 17:59:41.322687\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "opt_gradientboosting(learning_rate, 700, 1027, 3)\n",
    "end = datetime.datetime.now()\n",
    "print(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With best n_estimator = 700, increase the max_depth from 3 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.49736629144537836\n",
      "End\n",
      "2021-09-06 18:06:04.419571 2021-09-06 18:22:26.440966\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "opt_gradientboosting(learning_rate, 700, 1027, 5)\n",
    "end = datetime.datetime.now()\n",
    "print(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.5055125785324059\n",
      "End\n",
      "2021-09-06 18:30:01.482743 2021-09-06 18:55:31.624772\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "opt_gradientboosting(learning_rate, 700, 1027, 7)\n",
    "end = datetime.datetime.now()\n",
    "print(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Got best n_estimator = 700, max_depth = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.50426148134792\n",
      "End\n",
      "2021-09-06 19:15:59.209525 2021-09-06 20:21:57.988447\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "learning_rate = [0.1]\n",
    "opt_gradientboosting(learning_rate, 700, 1027, 10)\n",
    "end = datetime.datetime.now()\n",
    "print(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = 'teal'> Note: The performance decreased with increase in max_depth from 7 to 10.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.5040681217106112\n",
      "End\n",
      "2021-09-06 22:11:14.857542 2021-09-06 23:02:21.195565\n"
     ]
    }
   ],
   "source": [
    "#Let us decrease the features number and see the performance\n",
    "start = datetime.datetime.now()\n",
    "learning_rate = [0.1]\n",
    "opt_gradientboosting(learning_rate, 700, 900, 7)\n",
    "end = datetime.datetime.now()\n",
    "print(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.5048352956416153\n",
      "End\n",
      "2021-09-06 23:13:59.330348 2021-09-06 23:31:38.418384\n"
     ]
    }
   ],
   "source": [
    "# Let us decrease the features number and see the performance\n",
    "start = datetime.datetime.now()\n",
    "learning_rate = [0.1]\n",
    "opt_gradientboosting(learning_rate, 700, 500, 7)\n",
    "end = datetime.datetime.now()\n",
    "print(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.507286908005887\n",
      "End\n",
      "2021-09-06 23:58:59.503800 2021-09-07 00:07:07.683528\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "learning_rate = [0.1]\n",
    "opt_gradientboosting(learning_rate, 700, 400, 7)\n",
    "end = datetime.datetime.now()\n",
    "print(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.5071950830068808\n",
      "End\n",
      "2021-09-07 00:09:38.200982 2021-09-07 00:21:14.019333\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "learning_rate = [0.1]\n",
    "opt_gradientboosting(learning_rate, 700, 300, 7)\n",
    "end = datetime.datetime.now()\n",
    "print(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.5059793970267614\n",
      "End\n",
      "2021-09-07 00:27:56.265184 2021-09-07 00:38:40.548594\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "learning_rate = [0.1]\n",
    "opt_gradientboosting(learning_rate, 700, 200, 7)\n",
    "end = datetime.datetime.now()\n",
    "print(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.5042961247293202\n",
      "End\n",
      "2021-09-07 00:40:23.764514 2021-09-07 00:46:08.133291\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "learning_rate = [0.1]\n",
    "opt_gradientboosting(learning_rate, 700, 100, 7)\n",
    "end = datetime.datetime.now()\n",
    "print(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Among all models, Gradient boosting with learning_rate = 0.1, n_estimator = 700, max_features = 300, Max_depth = 7 is with highest r2_score value:0.507. Hence this model will be saved for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb6 = GradientBoostingRegressor(learning_rate = 0.1, n_estimators = 700,  max_features = 300, max_depth = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = 'teal'>To improve the models performanace, PCA was applied. Though it improved the Linear Regression model performance but it didn't help Random Forest Regeressor or Gradient Boosting Regressor. The PCA application and model optimization has been discussed in model Development Part-II and III**. <br><br>Both have been uploaed in Github in the following links:<br>https://github.com/damayantinaik/Springboard_Week_7_Capstone_Project_Netfilx/blob/main/Netflix_data_model_development_Part_II.ipynb <br> and <br> https://github.com/damayantinaik/Springboard_Week_7_Capstone_Project_Netfilx/blob/main/Netflix_data_model_development_PCAall_Part_III.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the best model parameter for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = gb6\n",
    "best_model.version = '1.0'\n",
    "best_model.pandas_version = pd.__version__\n",
    "best_model.numpy_version = np.__version__\n",
    "best_model.X_columns = [col for col in X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best model to disk\n",
    "import os\n",
    "import pickle\n",
    "pickle.dump(best_model, open('Best_model.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
